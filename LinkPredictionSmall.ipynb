{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyu7/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jyu7/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "PAPERNUM = 100000\n",
    "# 100,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/hrwwq3wn2ml3j1zbrk5s_x2m0000gp/T/ipykernel_70476/2038470307.py:2: DtypeWarning: Columns (1,4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('withRef.csv', nrows=PAPERNUM)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>reference_count</th>\n",
       "      <th>references</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>Preliminary Design of a Network Protocol Learn...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2005687710;2018037215</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-39476-8_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1674</td>\n",
       "      <td>A methodology for the physically accurate visu...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Conference</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1535888970;1992876689;1993710814;2035653341;20...</td>\n",
       "      <td>https://doi.org/10.2312/VAST/VAST11/137-144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1688</td>\n",
       "      <td>Comparison of GARCH, Neural Network and Suppor...</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Conference</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1560724230;1986968751;2156909104</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-11164-8_97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    id                                              title  \\\n",
       "0           0  1091  Preliminary Design of a Network Protocol Learn...   \n",
       "1           2  1674  A methodology for the physically accurate visu...   \n",
       "2           3  1688  Comparison of GARCH, Neural Network and Suppor...   \n",
       "\n",
       "     year n_citation    doc_type reference_count  \\\n",
       "0  2013.0          1  Conference             2.0   \n",
       "1  2011.0          1  Conference            15.0   \n",
       "2  2009.0          6  Conference             3.0   \n",
       "\n",
       "                                          references  \\\n",
       "0                              2005687710;2018037215   \n",
       "1  1535888970;1992876689;1993710814;2035653341;20...   \n",
       "2                   1560724230;1986968751;2156909104   \n",
       "\n",
       "                                            doi  \n",
       "0  https://doi.org/10.1007/978-3-642-39476-8_19  \n",
       "1   https://doi.org/10.2312/VAST/VAST11/137-144  \n",
       "2  https://doi.org/10.1007/978-3-642-11164-8_97  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('withRef.csv', nrows=PAPERNUM)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph and add nodes\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(df['id'].astype(str).tolist())\n",
    "df['references'] = df['references'].astype(str).apply(lambda x: x.strip().split(';') if x else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building graph: 100%|██████████| 100000/100000 [00:02<00:00, 47297.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add edges\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building graph\"):\n",
    "    for ref in row['references']:\n",
    "        if ref in G:\n",
    "            G.add_edge(row['id'], ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108077\n",
      "33303\n"
     ]
    }
   ],
   "source": [
    "# Graph shape\n",
    "print(len(G.nodes))\n",
    "print(len(G.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a fraction of edges for testing\n",
    "def train_test_split_graph(G, test_ratio=0.3, seed=52):\n",
    "    random.seed(seed)\n",
    "    edges = list(G.edges())\n",
    "    num_test = int(len(edges) * test_ratio)\n",
    "    test_edges = random.sample(edges, num_test)\n",
    "    train_graph = G.copy()\n",
    "    train_graph.remove_edges_from(test_edges)\n",
    "    return train_graph, test_edges\n",
    "\n",
    "G_train, test_edges = train_test_split_graph(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random node pairs that are not connected to evaluate false positives\n",
    "def generate_negative_edges(G, num_edges, excluded_edges):\n",
    "    nodes = list(G.nodes())\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < num_edges:\n",
    "        u, v = random.sample(nodes, 2)\n",
    "        if not G.has_edge(u, v) and (u, v) not in excluded_edges:\n",
    "            neg_edges.add((u, v))\n",
    "    return list(neg_edges)\n",
    "\n",
    "negative_edges = generate_negative_edges(G, len(test_edges), set(test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to undirected graphs\n",
    "G_undirected = G.to_undirected()\n",
    "G_train_undirected = G_train.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Common Neighbors: 772\n"
     ]
    }
   ],
   "source": [
    "# Common Neighbors\n",
    "pred_common = [\n",
    "    (u, v, len(list(nx.common_neighbors(G_train_undirected, u, v))))\n",
    "    for u, v in test_edges + negative_edges\n",
    "    if u in G_train_undirected and v in G_train_undirected and len(list(nx.common_neighbors(G_train_undirected, u, v))) > 0\n",
    "]\n",
    "print(f\"Number of Common Neighbors: {len(pred_common)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Jaccard Coefficient: 100%|██████████| 19980/19980 [00:00<00:00, 796265.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Jaccard Coefficient\n",
    "neighbors = {node: set(G_train_undirected.neighbors(node)) for node in G_train_undirected.nodes()}\n",
    "\n",
    "def fast_jaccard(u, v):\n",
    "    if u in neighbors and v in neighbors:\n",
    "        inter = neighbors[u] & neighbors[v]\n",
    "        union = neighbors[u] | neighbors[v]\n",
    "        return (u, v, len(inter) / len(union)) if union else (u, v, 0.0)\n",
    "    return (u, v, 0.0)\n",
    "\n",
    "pred_jaccard = [fast_jaccard(u, v) for u, v in tqdm(test_edges + negative_edges, desc=\"Calculating Jaccard Coefficient\", total=len(test_edges) + len(negative_edges))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamic-Adar Index\n",
    "pred_adamic = list(nx.adamic_adar_index(G_train_undirected, test_edges + negative_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - Jaccard: 0.5386\n",
      "AUC - Adamic-Adar: 0.5386\n"
     ]
    }
   ],
   "source": [
    "def evaluate_predictions(preds, true_edges_set):\n",
    "    y_true = [(u, v) in true_edges_set for u, v, _ in preds]\n",
    "    y_scores = [score for _, _, score in preds]\n",
    "    return roc_auc_score(y_true, y_scores)\n",
    "\n",
    "true_set = set(test_edges)\n",
    "auc_jaccard = evaluate_predictions(pred_jaccard, true_set)\n",
    "auc_adamic = evaluate_predictions(pred_adamic, true_set)\n",
    "\n",
    "# AUC scores\n",
    "print(f\"AUC - Jaccard: {auc_jaccard:.4f}\")\n",
    "print(f\"AUC - Adamic-Adar: {auc_adamic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction With LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight, fast\n",
    "\n",
    "def get_title(node):\n",
    "    if node not in df['id'].values:\n",
    "        return ''\n",
    "    title = df.loc[df['id'] == node, 'title'].values[0]\n",
    "    return title\n",
    "\n",
    "# Find unique nodes from edge pairs\n",
    "unique_nodes = set(u for u, _ in test_edges + negative_edges).union(\n",
    "               set(v for _, v in test_edges + negative_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding titles: 100%|██████████| 31229/31229 [06:53<00:00, 75.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute title embeddings for all nodes\n",
    "node_embeddings = {node: model.encode(get_title(node), convert_to_tensor=True) for node in tqdm(unique_nodes, desc=\"Encoding titles\", total=len(unique_nodes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating LLM scores: 100%|██████████| 19980/19980 [00:14<00:00, 1357.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity from embeddings\n",
    "def cached_score(u, v):\n",
    "    if u in node_embeddings and v in node_embeddings:\n",
    "        return util.cos_sim(node_embeddings[u], node_embeddings[v]).item()\n",
    "    return 0.5  # fallback for missing nodes\n",
    "\n",
    "# Generate predictions\n",
    "llm_preds = [(u, v, cached_score(u, v)) for u, v in tqdm(test_edges + negative_edges, desc=\"Calculating LLM scores\", total=len(test_edges) + len(negative_edges))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - SBERT: 0.7160\n"
     ]
    }
   ],
   "source": [
    "# AUC scores\n",
    "auc_sbert = evaluate_predictions(llm_preds, set(test_edges))\n",
    "print(f\"AUC - SBERT: {auc_sbert:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
